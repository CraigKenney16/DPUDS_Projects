{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Bi-Cluster Recommender and Clustering Algorithm\n","\n","This code can work for multiple datasets. The example shown is for a dataset that lists countries and contains average, per capital alcohol consumption for beer, wine, and other spirits. The Dendogram created clusters countries based on their similarity (Pearson, Euclid, or mixed).\n",""]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["###########################################\n","#                                         #\n","#     Bi-cluster Classifier for           #\n","#     similarity and recommendation       #\n","#                                         #\n","#     Created By: Sam Showalter           #\n","#     Creation Date: 5/28/2017            #\n","#                                         #\n","#     Cluster code modeled after          #\n","#     Programming Collective              #\n","#     Intelligence                        #\n","#     by Toby Segaran                     #\n","#                                         #\n","###########################################\n","\n","#Module imports and dependencies\n","import os\n","import pandas as pd\n","import math\n","from math import sqrt\n","from PIL import Image, ImageDraw"],"execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["#################################\n","#\n","#        Data Collection\n","#\n","#################################\n","\n","\n","#Path to data set. Change this so your data is in your working directory\n","path = \"/Users/Sam/Documents/Python/Recommender\"\n","os.chdir(path)\n","\n","#Import data. Change for your files as necessary\n","import_data = pd.read_csv('CountryA.csv')\n","\n","#Reset index to what you want to compare. Change name for your data\n","import_data.set_index('country', inplace = True)\n","\n","#Transposes data so that it can be more readily compared with TopMatches. Not necessary for cluster.\n","data = import_data.transpose()\n","\n","#Extract the row_names and column names of the data\n","row_names = data.columns.tolist()\n","col_names = data.index.tolist()\n","\n","\n","#Collect and formats raw data into lists. Each row represents attributes of an item that will be clustered.\n","raw_data = []\n","for i in data:\n","    raw_data.append(data[i].tolist())\n","\n","#Creates a dictionary of the data\n","data = data.to_dict()\n","\n",""],"execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["########################\n","#\n","#       Classes\n","#\n","########################\n","\n","#Cluster object used to compare data and make Dendogram\n","class bicluster():\n","    def __init__(self, vec,left = None, right = None, distance = 0.0, id = None):\n","        #Left child\n","        self.left = left\n","        #Right child\n","        self.right = right\n","        #Object vector\n","        self.vec = vec\n","        #Object id\n","        self.id = id\n","        #Object distance\n","        self.distance = distance\n","\n","\n",""],"execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["########################\n","#\n","#       Functions\n","#\n","########################\n","\n","#Euclidian distance correlation for TopMatches. Allows you to specify data source\n","def sim_Euclid(prefs, v1, v2):\n","\n","    #get the list of shared items\n","    si = {}\n","    for item in prefs[v1]:\n","        if item in prefs[v2]:\n","            si[item] = 1\n","            \n","    # if they have not ratings in common, return zero\n","    if len(si) == 0: \n","        return 0\n","    \n","    #Add up the squares of all of the differences\n","    sum_of_squares = sum([pow(prefs[v1][item] - prefs[v2][item],2) for item in prefs[v1] if item in prefs[v2]])\n","    \n","    euclid = math.sqrt(1/(1 + (sum_of_squares))) \n","\n","    return euclid\n","\n","#Pearson distance correlation for TopMatches. Allows you to specify data source\n","def sim_Pearson(data,p1,p2):\n","\n","    # Get the list of mutually rated items\n","    si = {}\n","    for item in data[p1]:\n","        if item in data[p2]: \n","            si[item]=1\n","\n","    # Find the number of elements\n","    n=len(si)\n","\n","    # if they are no ratings in common, return 0\n","    if n==0: return 0\n","\n","    # Add up all the preferences\n","    sum1=sum([data[p1][it] for it in si])\n","    sum2=sum([data[p2][it] for it in si])\n","\n","    # Sum up the squares\n","    sum1Sq=sum([pow(data[p1][it],2) for it in si])\n","    sum2Sq=sum([pow(data[p2][it],2) for it in si])\n","\n","    # Sum up the products\n","    pSum=sum([data[p1][it]*data[p2][it] for it in si])\n","\n","    # Calculate Pearson score fraction\n","    num = pSum - (sum1*sum2/n)\n","    den = sqrt((sum1Sq - pow(sum1,2)/n) * (sum2Sq - pow(sum2,2)/n))\n","\n","    #So you do not divide by zero\n","    if den == 0: return 0\n","\n","    #Calculate pearson correlation (r)\n","    pearson = num / den\n","\n","    return pearson\n","\n","#Euclidian distance correlation helper for the cluster algorithm. \n","def euclid(v1, v2):\n","\n","    #Add up the squares of all of the differences\n","    sum_of_squares = 0\n","    for i in range(len(v1)):\n","        sum_of_squares += pow((v1[i] - v2[i]),2)\n","    \n","    #If some of squares is zero, you want to ensure that dividing by zero does not ruin data\n","    if sum_of_squares == 0:\n","        #Hardcoded value to handle case of euclidian coefficient of zero.\n","        euclid = 0.000000000001\n","    else:\n","        euclid =  sum_of_squares\n","       \n","    return euclid\n","\n","#Gives pearson correlation coefficient between two points (r). Used as a cluster helper\n","def pearson(v1,v2):\n","\n","    #simple sums\n","    sum1 = sum(v1)\n","    sum2 = sum(v2)\n","    \n","    #Sum of the squares\n","    sum1Sq = sum([pow(v,2) for v in v1])\n","    sum2Sq = sum([pow(v,2) for v in v2])\n","    \n","    #Sum of the products\n","    pSum = sum([v1[i] * v2[i] for i in range(len(v1))])\n","    \n","    #Calculate r (Pearson Score)\n","    numerator = pSum - (sum1*sum2/len(v1))\n","    denominator = sqrt((sum1Sq - pow(sum1,2)/len(v1))*(sum2Sq - pow(sum2, 2)/len(v1)))\n","    if denominator == 0: return 0\n","    \n","    return 1.0 - numerator / denominator\n","\n","#Gives the most similar items for each value\n","def topMatches(data, value, n, similarity):\n","    #Gets top matches for each item\n","    res_list = [(similarity(data,value,other),other) for other in data if other != value]\n","    \n","    #Sort the similarity results\n","    res_list.sort()\n","    \n","    #Put result correlations in descending order\n","    res_list.reverse()\n","    \n","    #Can turn list into a dataframe for easier viewing\n","    res_list = pd.DataFrame(res_list)\n","    \n","    return res_list[0:n]\n"," \n","#Gives an average correlation between pearson and euclidian distance    \n","def combinedTopMatch(data,value,n):\n","    #Combines the different correlation coefficients to get the best fit\n","    res_list = [((sim_Pearson(data,value,other)+sim_Euclid(data,value,other))/2,other) for other in data if other != value]\n","    \n","    #Sort the similarity results\n","    res_list.sort()\n","    \n","    #Put result correlations in descending order\n","    res_list.reverse()\n","    \n","    #Can turn list into a dataframe for easier viewing\n","    res_list = pd.DataFrame(res_list)\n","    \n","    return res_list[0:n]\n","\n","\n","#Cluster algorithm. Can alter the method of comparison from pearson correlation to euclidian or mixed\n","def hcluster(rows, distance = pearson):\n","    distances = {}\n","    currentclustid = -1\n","    \n","    #clusters are initially just the rows\n","    clust = [bicluster(rows[i],id = i) for i in range(len(rows))]\n","    \n","    while len(clust) > 1:\n","        lowestpair = (0,1)\n","        closest  = distance(clust[0].vec,clust[1].vec)\n","        \n","        #loop through every pair looking for the smallest distance\n","        for i in range(len(clust)):\n","            for j in range(i + 1, len(clust)):\n","\n","                #Distances is the cache of distance calculations\n","                if (clust[i].id,clust[j].id) not in distances:                       \n","                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)\n","                    \n","                d = distances[(clust[i].id,clust[j].id)]\n","                \n","                if d < closest:          \n","                    closest = d          \n","                    lowestpair = (i,j)\n","                    \n","        # calculate the average of the two clusters    \n","        mergevec=[(clust[lowestpair[0]].vec[i] + clust[lowestpair[1]].vec[i])/2.0    \n","                  for i in range(len(clust[0].vec))]\n","                \n","        # create the new cluster    \n","        newcluster=bicluster(mergevec,left=clust[lowestpair[0]],                            \n","                        right=clust[lowestpair[1]],                       \n","                        distance=closest,id=currentclustid)\n","                                    \n","        # cluster ids that weren't in the original set are negative    \n","        currentclustid -= 1    \n","        del clust[lowestpair[1]]    \n","        del clust[lowestpair[0]]    \n","        clust.append(newcluster)\n","        \n","    return clust[0]\n","\n","#Prints the first n members of a certain cluster.\n","def printClust(clust, labels = None, n = 0):\n","    #Indent to make a hierarchy layout\n","    for i in range(n): print(\" \",)\n","    if clust.id < 0:\n","        #negative id means that this is a branch\n","        print(\"-\")\n","    else:\n","        #positive id means that this is an endpoint\n","        if labels == None: print(clust.id)\n","        else: print(labels[clust.id])\n","        \n","    #now print the left and right branches\n","    if clust.left!=None: printClust(clust.left,labels=labels,n=n+1)  \n","    if clust.right!=None: printClust(clust.right,labels=labels,n=n+1)\n","\n","#Gets the height of the dendogram\n","def getheight(clust):\n","    # Is this an endpoint? Then the height is just 1\n","    if clust.left==None and clust.right==None: return 1\n","    # Otherwise the height is the same of the heights of\n","    # each branch\n","    return getheight(clust.left)+getheight(clust.right)\n","\n","#Gets the depth of the dendogram\n","def getdepth(clust):\n","    #The distance of an endpoint is 0.0\n","    if clust.left==None and clust.right==None: return 0\n","    # The distance of a branch is the greater of its two sides\n","    # plus its own distance\n","    return max(getdepth(clust.left),getdepth(clust.right))+clust.distance\n","\n","#Draws a single node for the dendogram. Called recursively by drawdendogram\n","def drawnode(draw,clust,x,y,scaling,labels):\n","\n","    #If this is not an endpoint\n","    if clust.id<0:\n","\n","        #Get height of branches with children\n","        h1=getheight(clust.left)*20\n","        h2=getheight(clust.right)*20\n","\n","        #Get top and bottom values\n","        top=y-(h1+h2)/2\n","        bottom=y+(h1+h2)/2\n","\n","        # Line length\n","        ll=clust.distance*scaling\n","\n","        # Vertical line from this cluster to children\n","        draw.line((x,top+h1/2,x,bottom-h2/2),fill=(255,0,0))\n","\n","        # Horizontal line to left item\n","        draw.line((x,top+h1/2,x+ll,top+h1/2),fill=(255,0,0))\n","\n","        # Horizontal line to right item\n","        draw.line((x,bottom-h2/2,x+ll,bottom-h2/2),fill=(255,0,0))\n","\n","        # Call the function to draw the left and right nodes\n","        drawnode(draw,clust.left,x+ll,top+h1/2,scaling,labels)\n","        drawnode(draw,clust.right,x+ll,bottom-h2/2,scaling,labels)\n","    else:\n","        # If this is an endpoint, draw the item label\n","        draw.text((x + 5,y - 7),labels[clust.id],(0,0,0))\n","\n","\n","#Draws the dendogram. Calls the drawnode function recursively.\n","def drawdendrogram(clust,labels,pictype='clusters.jpg'):\n","     # height, width, and depth. Toy with these for aesthetics. \n","    h=getheight(clust)*27\n","    w=17000\n","    depth=getdepth(clust)\n","\n","    # width is fixed, so scale distances accordingly\n","    scaling=float(w-120)/depth\n","\n","    # Create a new image with a white background\n","    img=Image.new('RGB',(w,h),(255,255,255))\n","    draw=ImageDraw.Draw(img)\n","    draw.line((0,h/2,10,h/2),fill=(255,0,0))\n","\n","    # Draw the first node\n","    drawnode(draw,clust,10,(h/2),scaling,labels)\n","    img.save(pictype,'PNG')\n",""],"execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["#############################\n","#\n","#\n","#       Data Execution\n","#\n","#\n","#############################\n","\n","#print(topMatches(data,'USA',20,sim_Pearson))\n","#print(topMatches(data,'Germany',20,sim_Euclid))\n","#print(combinedTopMatch(data,'USA',20))\n","\n","#Create the cluster\n","clust=hcluster(raw_data,distance = euclid)\n","\n","#Print the cluster\n","#printClust(clust, labels = row_names)\n","\n","#Draw the dendogram of the cluster\n","drawdendrogram(clust,row_names,pictype='countryclust.png')\n","\n","print(\"Finished compiling.\")\n","\n",""],"execution_count":7,"outputs":[{"output_type":"stream","text":"Finished compiling.\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.0","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}